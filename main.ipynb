{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grokk_replica.datasets import AbstractDataset\n",
    "from grokk_replica.utils import combine_logs\n",
    "from grokk_replica.load_objs import load_item\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils import data\n",
    "from torch.utils.data import IterableDataset\n",
    "#from datasets import AbstractDataset\n",
    "#from utils import combine_logs\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "#from load_objs import load_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupDataset(IterableDataset):\n",
    "    def __init__(self, dataset: AbstractDataset, split: str):\n",
    "        super(GroupDataset, self).__init__()\n",
    "        assert split in {'train', 'val'}\n",
    "        self.dataset = dataset\n",
    "        self.split = split\n",
    "        self.fetch_f = None\n",
    "        if self.split == 'train':\n",
    "            self.fetch_f = self.dataset.fetch_train_example\n",
    "        elif self.split == 'val':\n",
    "            self.fetch_f = self.dataset.fetch_val_example\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        x, y, _ = self.fetch_f()\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/train_grokk.yaml\", \"r\") as fp:\n",
    "  config = yaml.safe_load(fp)\n",
    "\n",
    "with open(\"config/dataset/mod_subtract_dataset.yaml\", \"r\") as fp:\n",
    "  subtract_config = yaml.safe_load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    print('using config:', config)\n",
    "    train_cfg = config['train']\n",
    "    wandb_cfg = config['wandb']\n",
    "    if wandb_cfg['use_wandb']:\n",
    "        wandb.init(project=wandb_cfg['wandb_project'], config=config)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #print(f\"config[dataset] = {config['dataset']}\")\n",
    "    #dataset = load_item(config['dataset'])\n",
    "    #dataset = load_item(config[\"defaults\"][0][\"dataset\"])\n",
    "    dataset = load_item(subtract_config)\n",
    "    print(f\"subtract_config={subtract_config}\")\n",
    "    train_data = GroupDataset(dataset, 'train')\n",
    "    val_data = GroupDataset(dataset, 'val')\n",
    "    model = load_item(config['model'], dataset.n_vocab, dataset.n_out, device)\n",
    "    model.train()\n",
    "    train_dataloader = DataLoader(train_data, num_workers=train_cfg['num_workers'], batch_size=train_cfg['bsize'])\n",
    "    val_dataloader = DataLoader(val_data, num_workers=train_cfg['num_workers'], batch_size=train_cfg['bsize'])\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=train_cfg['lr'], \n",
    "                              weight_decay=train_cfg['weight_decay'], \n",
    "                              betas=train_cfg['betas'])\n",
    "    lr_schedule = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lambda s: min(s / train_cfg['warmup_steps'], 1))\n",
    "    step = 0\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        loss, logs = model.get_loss(x.to(device), y.to(device))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        lr_schedule.step()\n",
    "        if (step+1) % train_cfg['eval_every'] == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                all_val_logs = []\n",
    "                for i, (val_x, val_y) in tqdm(enumerate(val_dataloader)):\n",
    "                    if i >= train_cfg['eval_batches']:\n",
    "                        break\n",
    "                    _, val_logs = model.get_loss(val_x.to(device), val_y.to(device))\n",
    "                    all_val_logs.append(val_logs)\n",
    "            out_log = {'val': combine_logs(all_val_logs), 'train': combine_logs([logs]), 'step': (step+1), \n",
    "                       'lr': float(lr_schedule.get_last_lr()[0])}\n",
    "            print(out_log)\n",
    "            if wandb_cfg['use_wandb']:\n",
    "                wandb.log(out_log)\n",
    "            model.train()\n",
    "        step += 1\n",
    "        if train_cfg['max_steps'] is not None and step >= train_cfg['max_steps']:\n",
    "            break\n",
    "\n",
    "\n",
    "@hydra.main(config_path=\"./config\", config_name=\"train_grokk\")\n",
    "def main2(cfg : DictConfig):\n",
    "    cfg = OmegaConf.to_container(cfg)\n",
    "    train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
